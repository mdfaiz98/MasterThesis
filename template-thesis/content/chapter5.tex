% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
\chapter{Results and Discussion}


In this section, we present the results and a comprehensive analysis of the perceived stress levels experienced by human participants in various collsion avoidance strategies of our human-robot interaction study as well as the results from the best performing classifiers for our stress detection model.


\section{Assessment of Human Stress Levels}
\label{sec:result}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\columnwidth]{images/stress_levels_by_experiment.pdf}
	\caption{Stress levels by experiment}
	\label{fig:result1}
\end{figure}

In this section, we present a comprehensive analysis of the perceived stress levels experienced by human participants in various our human-robot interaction scenarios. \autoref{fig:result1} shows the 3 different stress levels experienced by participants in each of the 7 different experimental setups.
The different experimental scenarios represented are:
\begin{itemize}
    \item{\gls{NA-SW}}
    \item{\gls{NA-SHW}}
    \item{\gls{DA-SHW}}
    \item{\gls{PA-SHW}}
    \item{\gls{NA-DCW}}
    \item{\gls{DA-DCW}}
    \item{\gls{PA-DCW}}
\end{itemize}


In the \gls{NA-SW} scenario, the high prevalence of 'Not Stressed' responses is consistent with expectations that humans are most comfortable when working in an area separate from robots. Yet, the observation that 'High Stress' responses exceed those in scenarios with \gls{DA-SHW} and \gls{DA-DCW} may initially appear contradictory. A potential rationale for this will be discussed subsequently.

For \gls{NA-SHW}, there's a marked increase in stress levels, both 'Slightly Stressed' and 'Highly Stressed,' compared to the separated workspace \gls{NA-SW}. This is anticipated as sharing a workspace with robots, in the absence of any collision avoidance, could lead to increased safety concerns and unpredictability, thereby elevating stress levels.

Another common pattern that can be seen is that introduction of Dynamic (DA) and Predictive (PA) Collision Avoidance strategies in both Shared Workspace (SHW) and Direct Collaboration (DCW) scenarios has generally led to a reduction in stress levels, with a particularly noticeable decrease in the DCW scenarios. However, this trend is not as apparent at first in the Predictive Collision Avoidance in a Shared Workspace \gls{PA-SHW} scenario, where the number of 'Highly Stressed' instances is unexpectedly higher than in the scenario without collision avoidance (NA). It is important to consider that the overall count in the PA-SHW and No Collision Avoidance with Direct Collaboration in a Shared Workspace \gls{NA-DCW} scenarios as noted in the graph  is higher than in other contexts, which may have influenced the stress results.
This discrepancy suggests that tasks PA-SHW and NA-DCW required more time for completion, potentially skewing the perceived stress levels.

Efforts were made to standardise each task's difficulty and completion time, but the tasks involving \gls{PA-SHW} and \gls{NA-DCW} inherently took longer, likely due to the task design that included attaching wheels to the base items at four separate locations.(Refer \autoref{fig:task}). 
Interestingly, another experiment that involved attaching wheels to base items was NA-SW. However, because there was no delay for the human to wait for the robot to deliver parts, this may have counteracted the longer task time. Nevertheless, the requirement of attaching wheels might have contributed to increased frustration levels, potentially explaining the slightly higher count of 'Highly Stressed' in the NA-SW scenario.

The tasks with the fewest attachment points—Dynamic Collision Avoidance in a Shared Workspace \gls{DA-SHW} with five, and \gls{DA-DCW} with four—recorded the lowest counts of 'Highly Stressed' responses.

The diversity in task design was intentional to minimise the learning effects that could arise from performing similar tasks repeatedly. The goal was to create tasks that were distinct yet comparable in difficulty. The maximum number of attachment points was seven, with the minimum being four. However, it appears that this approach may have inadvertently introduced a variable of task complexity that was not adequately accounted for in the study's design.

Some other clear patterns shown are the increase of stress levels from the Dynamic Collision Avoidance (DA) to the Predictive Collision Avoidance (PA) in both the Shared workspace (SHW) and the Direct Collaboration (DCW) scenarios. A potential explanation for this pattern is that the Predictive Collision Avoidance system may not be finely calibrated for the range of human actions during the item handover task. This lack of precise parameter tuning leads to unpredictability in the robot's actions, which are based on future projections. The added complexity of the robot's behavior can contribute to higher stress levels for the human workers. During the experiments, variations in human behavior were observed. Some participants simply extended their hands to the robot for the handover, while others leaned in with their entire body, prompting the robot to misinterpret the action as a potential collision and retreat from the handover point for safety reasons. This forces the human to revert to their original position and attempt the handover again, leading to potential frustration and increased stress.

It's important to note that the optimization of the Predictive Collision Avoidance system's parameters was conducted prior to data collection, considering only a single standard behavior rather than the diverse behaviors of different participants. Future work could focus on refining the system to accommodate a wider range of human behaviors during handover tasks. Additionally, a hybrid approach that utilises Predictive Collision Avoidance for general tasks and switches to Dynamic Collision Avoidance for handovers is proposed as a potential solution to reduce stress. This approach is further discussed in the \autoref{sec:future}.


\section{Machine Learning Classification Models} 
In the evaluation of stress detection models, several machine learning algorithms were compared.
\subsection*{Support Vector Machine}
\gls{SVM} models with various kernel functions were employed. First a linear kernel was utilised with a regularization parameter (C) set to 1.0, enabling probability estimation. The SVM with Polynomial Kernel employed a polynomial kernel of degree 3, also with a regularization parameter of 1.0 and probability estimation enabled. Additionally, the SVM with \gls{RBF} Kernel utilised an RBF kernel with a regularization parameter of 1.0 and a gamma value of 0.1 for the kernel coefficient, allowing for probability estimation. Lastly, the SVM with Sigmoid Kernel employed a sigmoid kernel with a regularization parameter of 1.0 and a coefficient of 0.0. All models underwent evaluation using a 10-fold cross-validation technique. Detailed results, including mean scores and confusion matrices, can be found in \autoref{tab:scores} and the confusion matrices are shown in \autoref{fig:confusion_linear}, \autoref{fig:confusion_poly}, \autoref{fig:confusion_rbf}, \autoref{fig:confusion_sigmoid} respectively.

\begin{table}[hhtbp]
    \centering
    \begin{tabular}{|p{5cm}|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\ \hline
    \textbf{SVM Linear Kernel} & 0.628 & 0.622 & 0.630 & 0.628 & 0.805 \\
    \textbf{SVM Polynomial Kernel } & 0.750 & 0.745 & 0.803 & 0.750 & 0.946 \\
    \textbf{SVM RBF Kernel} & \textbf{0.916} & \textbf{0.915} & \textbf{0.926} & \textbf{0.916} & \textbf{0.994} \\
    \textbf{SVM Sigmoid Kernel} & 0.445 & 0.440 & 0.449 & 0.445 & 0.599 \\ \hline
    \end{tabular}
    \caption{Mean scores for SVM models with K-fold cross-validation ($k=10$)}
    \label{tab:scores}
    \end{table}


    \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.45\textwidth}
          \centering
          \includegraphics[width=\textwidth]{images/confusion_matrix_linear_svm.pdf}
          \caption{Confusion matrix for linear SVM}
          \label{fig:confusion_linear}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.45\textwidth}
          \centering
          \includegraphics[width=\textwidth]{images/confusion_matrix_poly_svm.pdf}
          \caption{Confusion matrix for polynomial SVM}
          \label{fig:confusion_poly}
        \end{minipage}
        \end{figure}
        
        \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.45\textwidth}
          \centering
          \includegraphics[width=\textwidth]{images/confusion_matrix_rbf.pdf}
          \caption{Confusion matrix for RBF SVM}
          \label{fig:confusion_rbf}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.45\textwidth}
          \centering
          \includegraphics[width=\textwidth]{images/confusion_matrix_sigmoid_svm.pdf}
          \caption{Confusion matrix for Sigmoid SVM}
          \label{fig:confusion_sigmoid}
        \end{minipage}
        \end{figure}
        
Among the models, the SVM with RBF Kernel achieved the highest mean scores across all metrics, including AUC, accuracy, F1 score, precision, and recall. This performance may be attributed to the RBF kernel's ability to capture non-linear relationships in the data effectively. 



\subsection*{Random Forest}
The results obtained from Random Forest models with different numbers of trees are shown in \autoref{tab:rf_scores} .The confusion matrices are shown in \autoref{fig:confusion_rf100}, \autoref{fig:confusion_rf200}.

\begin{table}[H]
    \centering
    \begin{tabular}{|p{5cm}|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\ \hline
    \textbf{Random Forest (n\_estimators=100)} & 0.949 & 0.949 & 0.950 & 0.949 & 0.992 \\
    \textbf{Random Forest (n\_estimators=200)} & 0.949 & 0.949 & 0.950 & 0.949 & 0.993 \\ \hline
    \end{tabular}
    \caption{Mean scores for random forest models with different numbers of sstimators}
    \label{tab:rf_scores}
\end{table}

    
    \begin{figure}[H]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
      \centering
      \includegraphics[width=\textwidth]{images/confusion_matrix_random_forest100.pdf}
      \caption{Confusion matrix for RF-100}
      \label{fig:confusion_rf100}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.45\textwidth}
      \centering
      \includegraphics[width=\textwidth]{images/confusion_matrix_random_forest200.pdf}
      \caption{Confusion matrix for RF-200}
      \label{fig:confusion_rf200}
    \end{minipage}
    \end{figure}

    Random Forest models, with different numbers of trees, showed consistent high performance. This indicates the model's robustness and reliability in handling the complexities of stress classification


\subsection*{Naive Bayes}
The Gaussian Naive Bayes classifier, with its assumption of feature independence, yielded moderate performance across various metrics, as shown in Table \ref{tab:nb_scores}. The confusion matrix is shown in \autoref{fig:naive}.

\begin{table}[hhtbp]
    \centering
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\
    \hline
    \textbf{Gaussian Naive Bayes} & 0.532 & 0.507 & 0.550 & 0.532 & 0.702 \\
    \hline
    \end{tabular}
    \caption{Mean scores for gaussian naive bayes with K-fold cross-validation ($k=10$)}
    \label{tab:nb_scores}
    \end{table}


    \begin{figure}[H]
        \centering
        \includegraphics[width=0.55\columnwidth]{images/confusion_matrix_naive_bayes.pdf}
        \caption{Confusion matrix for Gaussian Naive Bayes}
        \label{fig:naive}
    \end{figure}
    

    This model yielded moderate performance, likely due to its assumption of feature independence, which may not fully capture the complexities of stress indicators in human-robot interaction scenarios


\subsection*{k-Nearest Neighbors (k-NN)}
In this study, the k-Nearest Neighbors (k-NN) algorithm was utilised with varying values of the parameter k. The default distance metric used by k-NN, Euclidean distance, was employed for calculating the proximity between data points. Four different configurations of the k-NN model were examined, with k values set to 5, 10, 15, and 20, respectively. Each k-NN model underwent a 10-fold cross-validation procedure for evaluation. The results, including mean scores and confusion matrices, are presented in \autoref{tab:knn_scores} and \autoref{fig:confusion_knn_5}, \autoref{fig:confusion_knn_10}, \autoref{fig:confusion_knn_15}, \autoref{fig:confusion_knn_20} respectively.


\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\ \hline
    \textbf{k-NN (k=5)} & \textbf{0.909} & \textbf{0.909} & \textbf{0.913} & \textbf{0.909} & \textbf{0.982} \\
    \textbf{k-NN (k=10)} & 0.833 & 0.833 & 0.844 & 0.833 & 0.954 \\
    \textbf{k-NN (k=15)} & 0.780 & 0.779 & 0.795 & 0.780 & 0.924 \\
    \textbf{k-NN (k=20)} & 0.780 & 0.779 & 0.795 & 0.780 & 0.924 \\ \hline
    \end{tabular}
    \caption{Mean scores for k-NN Models with K-fold cross-validation ($k=10$)}
    \label{tab:knn_scores}
\end{table}

\begin{figure}[H]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_knn5.pdf}
        \caption{Confusion matrix for k-NN (k=5)}
        \label{fig:confusion_knn_5}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_knn10.pdf}
        \caption{Confusion matrix for k-NN (k=10)}
        \label{fig:confusion_knn_10}
    \end{minipage}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_knn15.pdf}
        \caption{Confusion matrix for k-NN (k=15)}
        \label{fig:confusion_knn_15}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_knn20.pdf}
        \caption{Confusion matrix for k-NN (k=20)}
        \label{fig:confusion_knn_20}
    \end{minipage}
\end{figure}

\subsection*{AdaBoost}
The AdaBoost models were trained using the AdaBoost classifier with varying numbers of estimators. Specifically, the models were configured with 50, 100, 150, and 200 estimators. The results, summarised in Table \ref{tab:adaboost_scores}.The confusion matrices, are presented in \autoref{fig:confusion_adaboost_50} and \autoref{fig:confusion_adaboost_100}, \autoref{fig:confusion_adaboost_150}, \autoref{fig:confusion_adaboost_200} respectively.


\begin{table}[H]
    \centering
    \begin{tabular}{|p{5cm}|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\ \hline
    \textbf{Adaboost (50)} & 0.647 & 0.644 & 0.653 & 0.647 & 0.814 \\
    \textbf{Adaboost (100)} & 0.702 & 0.701 & 0.708 & 0.702 & 0.829 \\
    \textbf{Adaboost (150)} & 0.720 & 0.718 & 0.724 & 0.720 & 0.844 \\
    \textbf{Adaboost (200)} & 0.732 & 0.731 & 0.736 & 0.732 & 0.849 \\ \hline
    \end{tabular}
    \caption{Mean scores for AdaBoost Models with Different Numbers of Estimators}
    \label{tab:adaboost_scores}
    \end{table}
    
    \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_adaboost50.pdf}
        \caption{Confusion matrix for AdaBoost (Estimators=50)}
        \label{fig:confusion_adaboost_50}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_adaboost100.pdf}
        \caption{Confusion matrix for AdaBoost (Estimators=100)}
        \label{fig:confusion_adaboost_100}
        \end{minipage}
        \end{figure}
        
        \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_adaboost150.pdf}
        \caption{Confusion matrix for AdaBoost (Estimators=150)}
        \label{fig:confusion_adaboost_150}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_adaboost200.pdf}
        \caption{Confusion matrix for AdaBoost (Estimators=200)}
        \label{fig:confusion_adaboost_200}
        \end{minipage}
        \end{figure}



\subsection*{Neural Netwrok -MLP}
Four MLP classifiers were trained with varying parameters to explore their impact on performance. The parameters used for each classifier are detailed in Table \ref{tab:mlp_params}. MLP-1 utilised a hidden layer size of 200 neurons, while MLP-2 had a hidden layer size of 100 neurons. Both MLP-1 and MLP-2 employed the Rectified Linear Unit (ReLU) activation function and the Adam solver, with an alpha value of 0.0008 and a maximum of 400 iterations. Additionally, MLP-3 and MLP-4 utilised logistic activation functions.

The mean scores for the MLP classifiers are presented in Table \ref{tab:mlp_scores}. Notably, MLP-3 achieved the highest accuracy, F1 score, precision, recall, and Area Under the Curve (AUC) among all models, indicating superior performance. The confusion matrices, are presented in \autoref{fig:confusion_mlp_1} and \autoref{fig:confusion_mlp_2}, \autoref{fig:confusion_mlp_3}, \autoref{fig:confusion_mlp_4} respectively.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Hidden Layer Sizes} & \textbf{Activation} & \textbf{Solver} & \textbf{Alpha} & \textbf{Max Iter}  \\
    \hline
    MLP-1 & (200,) & ReLU & adam & 0.0008 & 400  \\
    MLP-2 & (100,) & ReLU & adam & 0.0008 & 400  \\
    MLP-3 & (100,) & Logistic & adam & 0.0008 & 400  \\
    MLP-4 & (200,) & Logistic & adam & 0.0008 & 400  \\
    \hline
    \end{tabular}
    \caption{Parameters Used for MLP Classifiers}
    \label{tab:mlp_params}
    \end{table}
    
    \begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\
    \hline
    MLP-1 & 0.894 & 0.894 & 0.895 & 0.894 & 0.972 \\
    MLP-2 & 0.889 & 0.889 & 0.891 & 0.889 & 0.969 \\
    MLP-3 & \textbf{0.922} & \textbf{0.922} & \textbf{0.924} & \textbf{0.922} & \textbf{0.987} \\
    MLP-4 & 0.909 & 0.909 & 0.910 & 0.909 & 0.982 \\
    
    \hline
    \end{tabular}
    \caption{Mean scores for MLP classifiers}
    \label{tab:mlp_scores}
    \end{table}
    
    \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/confusion_matrix_mlp200.pdf}
            \caption{Confusion matrix for MLP-1}
            \label{fig:confusion_mlp_1}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/confusion_matrix_mlp100.pdf}
            \caption{Confusion matrix for MLP-2}
            \label{fig:confusion_mlp_2}
        \end{minipage}
    \end{figure}
    
    \begin{figure}[H]
        \centering
        \begin{minipage}[b]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/confusion_matrix_mlp100log.pdf}
            \caption{Confusion matrix for MLP-3}
            \label{fig:confusion_mlp_3}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/confusion_matrix_mlp200log.pdf}
            \caption{Confusion matrix for MLP-4}
            \label{fig:confusion_mlp_4}
        \end{minipage}
    \end{figure}
    
    Notably, MLP-3 demonstrated the highest performance across all the evaluated metrics, including accuracy, F1 score, precision, recall, and Area Under the Curve (AUC), indicating its superior ability to model the complex relationships inherent in the stress data. This success can be attributed to the effective combination of its parameters, particularly the logistic activation function and the optimised layer size, which facilitated the capture of nuanced patterns in the data.


    \autoref*{tab:summarised_scores} shows the summaries of all the models evaluated in this study.

    \begin{table}[H]
        \centering
        
        \begin{tabular}{|p{5cm}|c|c|c|c|c|}
        \hline
        \textbf{Model} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} \\ \hline
        SVM Linear Kernel & 0.628 & 0.622 & 0.630 & 0.628 & 0.805 \\
        SVM Polynomial Kernel & 0.750 & 0.745 & 0.803 & 0.750 & 0.946 \\
        SVM RBF Kernel & \textbf{0.916} & \textbf{0.915} & \textbf{0.926} & \textbf{0.916} & \textbf{0.994} \\
        SVM Sigmoid Kernel & 0.445 & 0.440 & 0.449 & 0.445 & 0.599 \\
        Random Forest (n\_estimators=100) & 0.949 & 0.949 & 0.950 & 0.949 & 0.992 \\
        Random Forest (n\_estimators=200) & 0.949 & 0.949 & 0.950 & 0.949 & 0.993 \\
        Gaussian Naive Bayes & 0.532 & 0.507 & 0.550 & 0.532 & 0.702 \\
        k-NN (k=5) & \textbf{0.909} & \textbf{0.909} & \textbf{0.913} & \textbf{0.909} & \textbf{0.982} \\
        k-NN (k=10) & 0.833 & 0.833 & 0.844 & 0.833 & 0.954 \\
        k-NN (k=15) & 0.780 & 0.779 & 0.795 & 0.780 & 0.924 \\
        k-NN (k=20) & 0.780 & 0.779 & 0.795 & 0.780 & 0.924 \\
        Adaboost (50) & 0.647 & 0.644 & 0.653 & 0.647 & 0.814 \\
        Adaboost (100) & 0.702 & 0.701 & 0.708 & 0.702 & 0.829 \\
        Adaboost (150) & 0.720 & 0.718 & 0.724 & 0.720 & 0.844 \\
        Adaboost (200) & 0.732 & 0.731 & 0.736 & 0.732 & 0.849 \\
        MLP-1 & 0.894 & 0.894 & 0.895 & 0.894 & 0.972 \\
        MLP-2 & 0.889 & 0.889 & 0.891 & 0.889 & 0.969 \\
        MLP-3 & \textbf{0.922} & \textbf{0.922} & \textbf{0.924} & \textbf{0.922} & \textbf{0.987} \\
        MLP-4 & 0.909 & 0.909 & 0.910 & 0.909 & 0.982 \\
        \hline
        \end{tabular}
        \caption{Summarised mean scores for various machine learning models}
        \label{tab:summarised_scores}
    \end{table}
    


























































































